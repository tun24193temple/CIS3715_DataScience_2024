{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Issue 1: Abortion, Votes: 36417718\n",
      "Issue 2: Gun Control, Votes: 36403324\n",
      "Issue 3: Immigration Healthcare, Votes: 35080040\n",
      "Issue 4: Obamacare, Votes: 35045122\n",
      "Issue 5: Gay Marriage, Votes: 34694807\n",
      "Issue 6: Marijuana, Votes: 33666167\n",
      "Issue 7: Minimum Wage, Votes: 27222318\n",
      "Issue 8: Terrorism, Votes: 26668564\n",
      "Issue 9: Common Core, Votes: 25008043\n",
      "Issue 10: Climate Change, Votes: 24709239\n",
      "Issue 11: Student Loans, Votes: 24568053\n",
      "Issue 12: Oil Drilling, Votes: 21665229\n",
      "Issue 13: Voter Fraud, Votes: 19317014\n",
      "Issue 14: Immigration, Votes: 17960706\n",
      "Issue 15: Death Penalty, Votes: 16815021\n",
      "Issue 16: Planned Parenthood Funding, Votes: 16750929\n",
      "Issue 17: Drug Policy, Votes: 16652861\n",
      "Issue 18: Border Security, Votes: 16106925\n",
      "Issue 19: Affirmative Action, Votes: 15442546\n",
      "Issue 20: Immigrant Laborers, Votes: 15275558\n",
      "Issue 21: Fracking, Votes: 14694486\n",
      "Issue 22: Equal Pay, Votes: 14456736\n",
      "Issue 23: Government Mandates, Votes: 14442932\n",
      "Issue 24: In-State Tuition, Votes: 14062445\n",
      "Issue 25: Government Spending, Votes: 13780538\n",
      "Issue 26: United Nations, Votes: 13696967\n",
      "Issue 27: Term Limits, Votes: 13162670\n",
      "Issue 28: Patriot Act, Votes: 12720697\n",
      "Issue 29: Solitary Confinement for Juveniles, Votes: 12411283\n",
      "Issue 30: Space Exploration, Votes: 11535512\n",
      "Issue 31: Medicaid, Votes: 11394560\n",
      "Issue 32: Religious Freedom Act, Votes: 10627243\n",
      "Issue 33: Criminal Voting Rights, Votes: 10370883\n",
      "Issue 34: Farm Subsidies, Votes: 10031374\n",
      "Issue 35: Alternative Energy, Votes: 9801554\n",
      "Issue 36: Israel, Votes: 9674717\n",
      "Issue 37: Mandatory Vaccinations, Votes: 9407584\n",
      "Issue 38: GMO Labels, Votes: 9300390\n",
      "Issue 39: Drones, Votes: 9284083\n",
      "Issue 40: Euthanasia, Votes: 8418419\n",
      "Issue 41: First Amendment, Votes: 8388005\n",
      "Issue 42: Immigrant Assimilation, Votes: 8364812\n",
      "Issue 43: No-Fly List Gun Control, Votes: 7843976\n",
      "Issue 44: Nuclear Energy, Votes: 7646089\n",
      "Issue 45: Police Body Cameras, Votes: 7639766\n",
      "Issue 46: Net Neutrality, Votes: 6140227\n",
      "Issue 47: Illegal Immigrant Detainment, Votes: 6120953\n",
      "Issue 48: Pension Reform, Votes: 6088880\n",
      "Issue 49: Gerrymandering, Votes: 5676426\n",
      "Issue 50: NSA Surveillance, Votes: 5472167\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.isidewith.com/polls/popular'\n",
    "response = requests.get(url)\n",
    "\n",
    "issues_votes = []\n",
    "\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    polls = soup.find_all('div', class_='poll')\n",
    "    \n",
    "    for poll in polls:\n",
    "        # Correctly identifying the issue name\n",
    "        img_div = poll.find('div', class_='img')\n",
    "        if img_div:\n",
    "            p_tag = img_div.find('p')\n",
    "            if p_tag:\n",
    "                span_tag = p_tag.find('span')\n",
    "                if span_tag:\n",
    "                    issue_name = span_tag.text.strip()\n",
    "\n",
    "                    # Adjusting logic for finding vote count\n",
    "                    count_div = poll.find('div', class_='count')\n",
    "                    if count_div:\n",
    "                        vote_text = count_div.text.strip().split()[0].replace(',', '')\n",
    "                        vote_count = int(vote_text) if vote_text.isdigit() else 0\n",
    "                        \n",
    "                        # Appending issue name and vote count to the list\n",
    "                        issues_votes.append((issue_name, vote_count))\n",
    "\n",
    "    # Sorting and extracting the top 100 issues based on vote count\n",
    "    issues_votes.sort(key=lambda x: x[1], reverse=True)\n",
    "    top_issues = issues_votes[:50]\n",
    "\n",
    "    iteration = 1\n",
    "    for issue, votes in top_issues:\n",
    "        print(f\"Issue {iteration}: {issue}, Votes: {votes}\")\n",
    "        iteration = iteration + 1\n",
    "else:\n",
    "    print(f\"Failed to fetch webpage: Status code {response.status_code}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Abortion', 'Gun Control', 'Immigration Healthcare', 'Obamacare', 'Gay Marriage', 'Marijuana', 'Minimum Wage', 'Terrorism', 'Common Core', 'Climate Change', 'Student Loans', 'Oil Drilling', 'Voter Fraud', 'Immigration', 'Death Penalty', 'Planned Parenthood Funding', 'Drug Policy', 'Border Security', 'Affirmative Action', 'Immigrant Laborers', 'Fracking', 'Equal Pay', 'Government Mandates', 'In-State Tuition', 'Government Spending', 'United Nations', 'Term Limits', 'Patriot Act', 'Solitary Confinement for Juveniles', 'Space Exploration', 'Medicaid', 'Religious Freedom Act', 'Criminal Voting Rights', 'Farm Subsidies', 'Alternative Energy', 'Israel', 'Mandatory Vaccinations', 'GMO Labels', 'Drones', 'Euthanasia', 'First Amendment', 'Immigrant Assimilation', 'No-Fly List Gun Control', 'Nuclear Energy', 'Police Body Cameras', 'Net Neutrality', 'Illegal Immigrant Detainment', 'Pension Reform', 'Gerrymandering', 'NSA Surveillance']\n"
     ]
    }
   ],
   "source": [
    "# Extract just the issue names from each tuple\n",
    "issues = [issue[0] for issue in top_issues]\n",
    "\n",
    "# Print out the list to verify\n",
    "print(issues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing instances: 100%|██████████| 77/77 [02:00<00:00,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11-Apr-24 20:47:46 - No instance specified, using random instance https://nitter.privacydev.net\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11-Apr-24 20:47:48 - Fetching error: Instance has been rate limited.Use another instance or try again later.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Print the keys of the first tweet object to see what data is available\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m test_tweets:\n\u001b[1;32m---> 11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAvailable keys in the tweet object:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mtest_tweets\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo tweets were returned, or there was an error in scraping.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "from ntscraper import Nitter\n",
    "\n",
    "# Initialize the scraper\n",
    "scraper = Nitter(log_level=1)\n",
    "\n",
    "# Scrape a few tweets for testing\n",
    "test_tweets = scraper.get_tweets(\"example\", mode='term', number=5)\n",
    "\n",
    "# Print the keys of the first tweet object to see what data is available\n",
    "if test_tweets:\n",
    "    print(\"Available keys in the tweet object:\", test_tweets[0].keys())\n",
    "else:\n",
    "    print(\"No tweets were returned, or there was an error in scraping.\")\n",
    "\n",
    "\n",
    "\n",
    "'''import subprocess\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "\n",
    "# Determine the timeframe for the past 30 days\n",
    "date_since = (datetime.now() - timedelta(days=90)).strftime('%Y-%m-%d')\n",
    "date_until = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "# Storage for tweet data\n",
    "tweets_data = []\n",
    "\n",
    "for issue in issues:\n",
    "    print(f\"Fetching tweets for: {issue}\")\n",
    "    \n",
    "    # snscrape command adjusted for timeframe and popularity (e.g., min_faves:500)\n",
    "    command = f'snscrape --jsonl --max-results 5 twitter-search \"{issue} since:{date_since} until:{date_until} min_faves:500 lang:en\"'\n",
    "    \n",
    "    # Execute the command\n",
    "    proc = subprocess.run(command, capture_output=True, text=True, shell=True)\n",
    "    fetched_tweets = proc.stdout.strip().split('\\n')\n",
    "    \n",
    "    for tweet_json in fetched_tweets:\n",
    "        tweet = json.loads(tweet_json)\n",
    "        tweets_data.append({\n",
    "            'tweet': tweet.get('content'),\n",
    "            'likes': tweet.get('likeCount'),\n",
    "            'reposts': tweet.get('retweetCount'),\n",
    "            'issue': issue,\n",
    "            'url': tweet.get('url'),\n",
    "            'date': tweet.get('date'),\n",
    "            # Follower count is not available through snscrape, would need to use Twitter API for that\n",
    "        })\n",
    "\n",
    "# Displaying the first few entries for verification\n",
    "for tweet in tweets_data[:5]:\n",
    "    print(tweet)\n",
    "\n",
    "# Convert the collected data into a pandas DataFrame\n",
    "df = pd.DataFrame(tweets_data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "csv_file_path = 'collected_tweets_data.csv'\n",
    "df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(f\"Data saved to {csv_file_path}\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "Forbidden",
     "evalue": "403 Forbidden\nWhen authenticating requests to the Twitter API v2 endpoints, you must use keys and tokens from a Twitter developer App that is attached to a Project. You can create a project via the developer portal.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mForbidden\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 22\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Fetch tweets\u001b[39;00m\n\u001b[0;32m     17\u001b[0m tweets \u001b[38;5;241m=\u001b[39m tweepy\u001b[38;5;241m.\u001b[39mPaginator(client\u001b[38;5;241m.\u001b[39msearch_recent_tweets, \n\u001b[0;32m     18\u001b[0m                           query\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00missue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m -is:retweet lang:en\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m     19\u001b[0m                           tweet_fields\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpublic_metrics\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauthor_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcreated_at\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     20\u001b[0m                           max_results\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mflatten(limit\u001b[38;5;241m=\u001b[39mtweets_per_issue)\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtweet\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtweets\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mtry\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[43mauthor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_user\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtweet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauthor_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_fields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpublic_metrics\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Tim\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tweepy\\pagination.py:67\u001b[0m, in \u001b[0;36mPaginator.flatten\u001b[1;34m(self, limit)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     66\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 67\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mPaginationIterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mResponse\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Tim\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tweepy\\pagination.py:126\u001b[0m, in \u001b[0;36mPaginationIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpagination_token\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m pagination_token\n\u001b[1;32m--> 126\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, Response):\n\u001b[0;32m    129\u001b[0m     meta \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mmeta\n",
      "File \u001b[1;32mc:\\Users\\Tim\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tweepy\\client.py:1266\u001b[0m, in \u001b[0;36mClient.search_recent_tweets\u001b[1;34m(self, query, user_auth, **params)\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"search_recent_tweets( \\\u001b[39;00m\n\u001b[0;32m   1175\u001b[0m \u001b[38;5;124;03m    query, *, end_time=None, expansions=None, max_results=None, \\\u001b[39;00m\n\u001b[0;32m   1176\u001b[0m \u001b[38;5;124;03m    media_fields=None, next_token=None, place_fields=None, \\\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1263\u001b[0m \u001b[38;5;124;03m.. _Academic Research Project: https://developer.twitter.com/en/docs/projects\u001b[39;00m\n\u001b[0;32m   1264\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1265\u001b[0m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m query\n\u001b[1;32m-> 1266\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1267\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/2/tweets/search/recent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint_parameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1269\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mend_time\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexpansions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_results\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmedia.fields\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1270\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnext_token\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mplace.fields\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpoll.fields\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1271\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msince_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msort_order\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstart_time\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtweet.fields\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1272\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muntil_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser.fields\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m   1273\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTweet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_auth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_auth\u001b[49m\n\u001b[0;32m   1274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Tim\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tweepy\\client.py:129\u001b[0m, in \u001b[0;36mBaseClient._make_request\u001b[1;34m(self, method, route, params, endpoint_parameters, json, data_type, user_auth)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_make_request\u001b[39m(\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28mself\u001b[39m, method, route, params\u001b[38;5;241m=\u001b[39m{}, endpoint_parameters\u001b[38;5;241m=\u001b[39m(), json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    125\u001b[0m     data_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, user_auth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    126\u001b[0m ):\n\u001b[0;32m    127\u001b[0m     request_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_params(params, endpoint_parameters)\n\u001b[1;32m--> 129\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroute\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_auth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_auth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_type \u001b[38;5;129;01mis\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mResponse:\n\u001b[0;32m    133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\Tim\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tweepy\\client.py:100\u001b[0m, in \u001b[0;36mBaseClient.request\u001b[1;34m(self, method, route, params, json, user_auth)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Unauthorized(response)\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m403\u001b[39m:\n\u001b[1;32m--> 100\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Forbidden(response)\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m404\u001b[39m:\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFound(response)\n",
      "\u001b[1;31mForbidden\u001b[0m: 403 Forbidden\nWhen authenticating requests to the Twitter API v2 endpoints, you must use keys and tokens from a Twitter developer App that is attached to a Project. You can create a project via the developer portal."
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize Tweepy client with your bearer token\n",
    "my_bearer_token = 'AAAAAAAAAAAAAAAAAAAAADG0tAEAAAAAyorYuRtjH4iMWgrLSXHucL22JhY%3DtmlXuDLwaUyPx0wkFmlOvQdUe57wANjeWsTCR8tvsSZ5bvRfOl'\n",
    "client = tweepy.Client(bearer_token=my_bearer_token)\n",
    "\n",
    "# Prepare a list to collect data\n",
    "tweets_data = []\n",
    "\n",
    "# Calculate the number of tweets to fetch per issue based on your total limit and number of issues\n",
    "tweets_per_issue = 1\n",
    "\n",
    "issue = 'abortion'\n",
    "\n",
    "# Fetch tweets\n",
    "tweets = tweepy.Paginator(client.search_recent_tweets, \n",
    "                          query=f\"{issue} -is:retweet lang:en\", \n",
    "                          tweet_fields=['public_metrics', 'author_id', 'created_at'],\n",
    "                          max_results=1).flatten(limit=tweets_per_issue)\n",
    "\n",
    "for tweet in tweets:\n",
    "    try:\n",
    "        author = client.get_user(id=tweet.author_id, user_fields=['public_metrics'])\n",
    "        tweets_data.append({\n",
    "            'tweet': tweet.text,\n",
    "            'likes': tweet.public_metrics['like_count'],\n",
    "            'reposts': tweet.public_metrics['retweet_count'],\n",
    "            'follower_count': author.data.public_metrics['followers_count'],\n",
    "            'issue': issue\n",
    "        })\n",
    "    except tweepy.TweepyException as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Convert the collected data into a pandas DataFrame\n",
    "df = pd.DataFrame(tweets_data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('tweets_issues_data.csv', index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
